% \outline{Social news matching project}

Many computational social science projects examine online discourse surrounding a specific event, such as natural disasters, sporting matches, and political events. During our project above, I realized that a costly bottleneck in similar work is identifying relevant social media posts. Normally, an initial corpus would be collected using a high-recall, low-precision keyword search, and filtered manually by human judges. I instead devised a distantly supervised approach by leveraging Reddit comments and tweets associated with news articles as a relevance signal. I used triplet loss to minimize the distance between embeddings of articles and their comments, allowing other researchers to filter corpora by selecting comments most similar to news articles describing the event of interest. The length of the news articles presented many challenges, which I countered with an efficient variant of the Transformer architecture. This saved us thousands of dollars in annotation costs, and I enjoyed working with tens of thousands of documents and learned a lot about representation learning.